{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b57b0ba709768a7bbbc5b5f9f052a7cbe42e1ac711dd327dca942e98c95c92b1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Intermovie - projet 6 \n",
    "Utilisation de dataframes pour manipuler des données. Exportation en CSV pour chaque dataframe créé. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import des librairies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from MODULES.loader import IntermovieDataLoader\n",
    "from MODULES.prediction import IntermoviePrediction\n",
    "from MODULES.my_timer import MyTimer\n",
    "timer = MyTimer()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "## Paramètrage général"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../datas/movies_dataset/'\n",
    "CURATED_PATH = '../datas/CURATED/'\n",
    "WORKS = 'WORKS/'\n",
    "FORMATS = 'FORMATS/'\n",
    "REGIONS = 'REGIONS/'\n",
    "nb_votes = 500\n",
    "\n",
    "data_loader = IntermovieDataLoader()"
   ]
  },
  {
   "source": [
    "## Import et nettoyage des datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Téléchargement et dezip du dataset\n",
    "data_loader.ensure_data_loaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Chargement de title.principals.tsv :\nElapsed time: 56.8991 seconds\nChargement de title.ratings.tsv :\nElapsed time: 1.7872 seconds\nChargement de title.basics.tsv :\nElapsed time: 63.5592 seconds\nChargement title.akas.tsv :\nElapsed time: 36.2197 seconds\nChargement name.basics.tsv :\nElapsed time: 59.0370 seconds\nNettoyage du dataset :\nElapsed time: 156.6974 seconds\n"
    }
   ],
   "source": [
    "# Import des datasets originaux.\n",
    "timer.start()\n",
    "title_principals = pd.read_csv(DATASET_PATH + \"title.principals.tsv\", sep='\\t', index_col='tconst', usecols=['nconst', 'tconst', 'category'], encoding='utf-8')\n",
    "timer.stop(\"Title.principals.tsv importé.\")\n",
    "\n",
    "timer.start()\n",
    "title_ratings = pd.read_csv(DATASET_PATH + \"title.ratings.tsv\", sep='\\t', index_col='tconst', encoding='utf-8')\n",
    "timer.stop(\"\\nTitle.ratings.tsv importé.\")\n",
    "\n",
    "timer.start()\n",
    "title_basics = pd.read_csv(DATASET_PATH + \"title.basics.tsv\", sep='\\t', index_col='tconst', usecols=['tconst', 'titleType', 'primaryTitle', 'originalTitle', 'genres'], encoding='utf-8')\n",
    "timer.stop(\"\\nTitle.basics.tsv importé.\")\n",
    "\n",
    "timer.start()\n",
    "title_akas = pd.read_csv(DATASET_PATH + \"title.akas.tsv\", sep='\\t', index_col='titleId', usecols=['titleId', 'title', 'region', 'isOriginalTitle'], encoding='utf-8')\n",
    "timer.stop(\"\\nTitle.akas.tsv importé.\")\n",
    "\n",
    "timer.start()\n",
    "name_basics = pd.read_csv(DATASET_PATH + \"name.basics.tsv\", sep='\\t', index_col='nconst', usecols=['nconst', 'primaryName', 'primaryProfession'], encoding='utf-8')\n",
    "timer.stop(\"\\nName.basics.tsv importé.\")\n",
    "\n",
    "# Nettoyage des datasets importés.\n",
    "timer.start()\n",
    "title_principals = title_principals.dropna()\n",
    "title_principals = title_principals[['nconst']][title_principals['category'].str.contains(\"actor|actress\", regex=True)]\n",
    "\n",
    "title_ratings = title_ratings.dropna()\n",
    "\n",
    "title_basics = title_basics[title_basics.genres != '\\\\N'].dropna()\n",
    "title_basics = title_basics[title_basics.titleType.str.contains('movie|tvMovie', regex=True)]\n",
    "\n",
    "title_akas = title_akas.dropna()\n",
    "title_akas = title_akas.replace('\\\\N', np.nan)\n",
    "\n",
    "name_basics = name_basics.dropna()\n",
    "name_basics = name_basics[['primaryName']][name_basics.primaryProfession.str.contains('actor|actress', regex=True)]\n",
    "timer.stop(\"\\nNettoyage du dataset :\")\n",
    "\n",
    "# Création d'un dataframe comportant les régions originales des films (et export en CSV).\n",
    "original_titles = title_akas[title_akas.isOriginalTitle==1]['title'].to_frame()\n",
    "original_titles = original_titles.merge(title_akas[['title', 'region']], how=\"left\", right_on=['titleId', 'title'], left_on=['titleId', 'title'])\n",
    "original_titles = original_titles.dropna()\n",
    "original_titles = original_titles.reset_index().drop_duplicates(subset=\"titleId\", keep = \"first\").set_index('titleId')\n",
    "original_titles.to_csv(CURATED_PATH + 'original_titles_regions.csv')\n",
    "\n",
    "# Splits des datasets (utilisés dans les bonus):\n",
    "data_loader.split_data_role()\n",
    "data_loader.split_data_type()\n",
    "data_loader.split_data_origine()\n"
   ]
  },
  {
   "source": [
    "## 1. Sélection de la liste des acteurs par films"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_movies = title_principals.merge(name_basics, right_index=True, left_on=['nconst'], how='left')\n",
    "actors_movies = actors_movies.merge(title_basics[['primaryTitle']], right_index=True, left_on=['tconst'], how='left')\n",
    "actors_movies = actors_movies.dropna()\n",
    "actors_movies = actors_movies[['primaryTitle', 'primaryName']]\n",
    "actors_movies = actors_movies.groupby('primaryTitle').agg({'primaryName': ', '.join})\n",
    "\n",
    "# Export en CSV\n",
    "actors_movies.to_csv(CURATED_PATH + 'actors_movies.csv')"
   ]
  },
  {
   "source": [
    "## 2. La liste des films Américains (en gardant leur nom en français) et leur note moyenne"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_akas_fr = title_akas[title_akas['region'].str.contains('FR')].drop(columns=['region'])\n",
    "\n",
    "american_movies = title_akas_fr.merge(title_basics[['originalTitle']], how='left', left_index=True, right_index=True)\n",
    "american_movies = american_movies.dropna()\n",
    "\n",
    "american_movies = american_movies.merge(title_ratings[['averageRating']], how='left', left_index=True, right_index=True)\n",
    "american_movies = american_movies.dropna()\n",
    "\n",
    "# Export en CSV :\n",
    "american_movies.to_csv(CURATED_PATH + 'american_movies.csv', index=False)\n"
   ]
  },
  {
   "source": [
    "## 3. La note moyenne des différents genres"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CSV/mean_genre.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1e080ea0a46e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Export en CSV :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mmean_genre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CSV/mean_genre.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3165\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3166\u001b[0m         )\n\u001b[1;32m-> 3167\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m             )\n\u001b[0;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CSV/mean_genre.csv'"
     ]
    }
   ],
   "source": [
    "temporary = title_basics[['genres']].merge(title_ratings, how='left', left_index=True, right_index=True)\n",
    "temporary = temporary.dropna()\n",
    "temporary = temporary[temporary.genres != '\\\\N']\n",
    "\n",
    "mean_genre = pd.DataFrame(temporary.genres.str.split(',').tolist(), index=temporary.index).stack()\n",
    "mean_genre = mean_genre.reset_index(['tconst', 0])\n",
    "\n",
    "temporary = temporary.drop(columns=['genres'])\n",
    "\n",
    "mean_genre = mean_genre.set_index('tconst')\n",
    "mean_genre.columns = ['genre']\n",
    "\n",
    "mean_genre = mean_genre.merge(temporary, how='left', left_index=True, right_index=True)\n",
    "mean_genre = mean_genre[mean_genre.genre != '\\\\N']\n",
    "\n",
    "mean_genre = mean_genre.groupby('genre').mean()\n",
    "\n",
    "mean_genre = mean_genre.sort_values(by=['averageRating'], ascending=False)\n",
    "mean_genre['averageRating'] = mean_genre['averageRating'].map('{:,.2f}'.format)\n",
    "\n",
    "# Export en CSV :\n",
    "mean_genre.to_csv(CURATED_PATH + 'mean_genre.csv')"
   ]
  },
  {
   "source": [
    "## 4. La note moyenne de chaque acteur par rapport aux films dans lesquels il apparaît"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_ranking = title_principals[['nconst']].merge(title_basics[['titleType']], left_index=True, right_index=True, how='left').drop(columns='titleType').dropna()\n",
    "actors_ranking = actors_ranking.merge(name_basics, left_on='nconst', right_index=True, how='left').dropna()\n",
    "actors_ranking = actors_ranking.merge(title_ratings, left_index=True, right_on=['tconst'], how='left')[['averageRating', 'primaryName']].dropna()\n",
    "actors_ranking = actors_ranking.groupby('primaryName').agg({'averageRating': 'mean'})\n",
    "actors_ranking['averageRating'] = actors_ranking['averageRating'].map('{:,.2f}'.format)\n",
    "\n",
    "# Export en CSV :\n",
    "actors_ranking.to_csv(CURATED_PATH + 'rating_actors.csv')"
   ]
  },
  {
   "source": [
    "# Partie Bonus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3. Prediction des notes moyennes de films basées sur diverses paramètres"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un dataset comportant le scaractéristiques de tous les films avec leur note moyenne.\n",
    "\n",
    "actors = pd.concat([pd.read_csv(CURATED_PATH + WORKS + 'actor.csv', delimiter=',', usecols=['tconst', 'nconst'], index_col = ['tconst']), pd.read_csv(CURATED_PATH + WORKS + 'actress.csv', delimiter=',', usecols=['tconst', 'nconst'], index_col = ['tconst'])])\n",
    "actors = actors.rename(columns={\"nconst\": \"actors\"})\n",
    "\n",
    "movies = pd.read_csv(CURATED_PATH + FORMATS + 'movie.csv', delimiter=',', usecols=['tconst', 'isAdult', 'startYear', 'runtimeMinutes', 'genres'], index_col = ['tconst'])\n",
    "movies = movies[movies.runtimeMinutes != '\\\\N'][movies.genres != '\\\\N']\n",
    "\n",
    "dataset = actors.merge(movies, how='right', left_index=True, right_index=True)\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset.assign(genres=dataset['genres'].str.split(',')).explode('genres')\n",
    "\n",
    "producers = pd.read_csv(CURATED_PATH + WORKS + 'producer.csv', delimiter=',', usecols=['tconst', 'nconst'], index_col = ['tconst'])\n",
    "producers = producers.rename(columns={\"nconst\": \"producer\"})\n",
    "\n",
    "writers = pd.read_csv(CURATED_PATH + WORKS + 'writer.csv', delimiter=',', usecols=['tconst', 'nconst'], index_col = ['tconst'])\n",
    "writers = writers.rename(columns={\"nconst\": \"writer\"})\n",
    "\n",
    "composers = pd.read_csv(CURATED_PATH + WORKS + 'composer.csv', delimiter=',', usecols=['tconst', 'nconst'], index_col = ['tconst'])\n",
    "composers = composers.rename(columns={\"nconst\": \"composer\"})\n",
    "\n",
    "producers = producers.merge(writers, how=\"inner\", left_index=True, right_index=True)\n",
    "producers = producers.merge(composers, how=\"inner\", left_index=True, right_index=True)\n",
    "dataset = dataset.merge(producers, how=\"left\", left_index=True, right_index=True)\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "dataset = dataset.merge(original_titles[['region']], how=\"left\", right_index=True, left_index=True)\n",
    "\n",
    "rated_movies = title_ratings[title_ratings.numVotes  > nb_votes]\n",
    "rated_movies = rated_movies[['averageRating']]\n",
    "dataset = dataset.merge(rated_movies, how='left', left_index=True, right_index=True)\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# Export en CSV :\n",
    "dataset.to_csv(CURATED_PATH + 'movies_infos.csv')"
   ]
  }
 ]
}